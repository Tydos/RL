{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Prasad Jawale RL Experiment 1 - Q Learning"],"metadata":{"id":"HJmG5EAQCih1"}},{"cell_type":"markdown","source":["**Enviroment 4x4**\n","\n","S - start state\n","X - obstacle\n","R - reward\n","G - goal state\n","\n","S . . R\n","\n",". X X .\n","\n",". . X .\n","\n","R . . G"],"metadata":{"id":"PKhBTxD3LMrH"}},{"cell_type":"code","source":["import numpy as np\n","\n","grid_size = 4\n","start_state = (0, 0)\n","goal_state = (grid_size - 1, grid_size - 1)\n","obstacles = [(1, 1),(1,2),(2, 2)]\n","reward_state = [(0, 3), (3, 0)]\n","\n","actions = ['up', 'down', 'left', 'right']\n","num_actions = len(actions)\n","\n","learning_rate = 0.2\n","discount_factor = 0.8\n","epsilon = 0.2\n","num_episodes = 1500\n","\n","Q_values = np.zeros((grid_size, grid_size, num_actions))\n","\n","def get_next_state(state, action):\n","    x, y = state\n","    if action == 'up':\n","        return max(x - 1, 0), y\n","    elif action == 'down':\n","        return min(x + 1, grid_size - 1), y\n","    elif action == 'left':\n","        return x, max(y - 1, 0)\n","    elif action == 'right':\n","        return x, min(y + 1, grid_size - 1)\n","\n","def environment(state, action):\n","    if state in reward_state:\n","        return 10\n","    if state == goal_state:\n","        return 0\n","    next_state = get_next_state(state, action)\n","    if next_state in obstacles:\n","        return -5\n","    elif next_state == goal_state:\n","        return 100\n","    else:\n","        return -1\n","\n","def select_action(state):\n","    if np.random.rand() < epsilon:\n","        return np.random.choice(actions)\n","    else:\n","        return actions[np.argmax(Q_values[state])]\n","\n","def update_Q_value(state, action, reward, next_state):\n","    max_next_Q_value = np.max(Q_values[next_state])\n","    Q_values[state][actions.index(action)] += learning_rate * (reward + discount_factor * max_next_Q_value - Q_values[state][actions.index(action)])\n","\n","for episode in range(num_episodes):\n","    state = start_state\n","    while state != goal_state:\n","        action = select_action(state)\n","        reward = environment(state, action)\n","        next_state = get_next_state(state, action)\n","        update_Q_value(state, action, reward, next_state)\n","        state = next_state\n","\n","print(\"Learned Q-values:\")\n","print(Q_values)\n","\n","path = []\n","state = start_state\n","while state != goal_state:\n","    action = actions[np.argmax(Q_values[state])]\n","    path.append((state, action))\n","    state = get_next_state(state, action)\n","path.append((goal_state, None))\n","\n","print(\"\\nShortest Path:\")\n","for step in path:\n","    print(step)\n"],"metadata":{"id":"6UBNhkxHCd99","executionInfo":{"status":"ok","timestamp":1707890403612,"user_tz":-330,"elapsed":697,"user":{"displayName":"PRASAD JAWALE","userId":"08908178032325548227"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"611506e9-c0b5-4388-b613-a897a5e254f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Learned Q-values:\n","[[[ 27.03071974  34.51701703  27.03072     35.0384    ]\n","  [ 35.0384      23.03071735  27.03071993  45.048     ]\n","  [ 45.04799979  44.75999638  35.03839872  57.56      ]\n","  [ 68.55999989  73.2         56.04799995  68.55999996]]\n","\n"," [[ 23.25427666  44.81733464  25.16627379  18.42610145]\n","  [ 35.03839997  21.25125816  16.70970592  24.5962335 ]\n","  [ 45.04776902  48.93062588  21.90706886  62.2       ]\n","  [ 57.56        79.          44.75999905  62.19999997]]\n","\n"," [[ 29.26118853  57.47069761  36.39218439  29.83220217]\n","  [ 16.71624053  58.10073926  22.2308224   24.30619061]\n","  [ 44.7576809   21.11212669  24.42515447  78.99970368]\n","  [ 62.19999984 100.          58.19237447  78.99999952]]\n","\n"," [[ 45.78246798  56.16069236  57.79524282  73.18503834]\n","  [ 31.38567323  41.71509994  51.41940577  78.99649368]\n","  [ 47.97693954  45.0253403   25.9000577   99.99953232]\n","  [  0.           0.           0.           0.        ]]]\n","\n","Shortest Path:\n","((0, 0), 'right')\n","((0, 1), 'right')\n","((0, 2), 'right')\n","((0, 3), 'down')\n","((1, 3), 'down')\n","((2, 3), 'down')\n","((3, 3), None)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"J7euPjvYMd_e"},"execution_count":null,"outputs":[]}]}