{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1dDnEO91POin5vbPSMKRQxNVeJDyppzZO","timestamp":1711866498274}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Prasad Jawale RL Experiment 7 - Dynamic Programming\n"],"metadata":{"id":"Hsg3g5HoVK29"}},{"cell_type":"code","source":["import numpy as np\n","\n","NUM_STATES = 21\n","MAX_CARS = 10\n","RENTAL_COST = 2\n","EMPLOYEE_TRANSFER = 1\n","EXTRA_PARKING_COST = 4\n","DISCOUNT_FACTOR = 0.9\n","\n","\n","def reward(state, action):\n","  cars_moved = min(action, state)\n","  cars_left = state - cars_moved\n","  cars_right = action - cars_moved\n","\n","  reward = 0\n","\n","  if cars_moved > 0:\n","    reward -= RENTAL_COST * EMPLOYEE_TRANSFER\n","\n","  reward += RENTAL_COST * (cars_moved - EMPLOYEE_TRANSFER)\n","\n","  if cars_left > MAX_CARS:\n","    reward -= EXTRA_PARKING_COST\n","  if cars_right > MAX_CARS:\n","    reward -= EXTRA_PARKING_COST\n","\n","  return reward\n","\n","\n","def transition_probability(state, action):\n","  epsilon = 1e-8\n","  num_actions = min(state, NUM_STATES - state)\n","  if num_actions == 0:\n","    num_actions = 1\n","  probability = 1 / (num_actions + epsilon)\n","  P = np.zeros((NUM_STATES, NUM_STATES))\n","  for next_state in range(NUM_STATES):\n","    if abs(next_state - state) <= action:\n","      P[state, next_state] = probability\n","  return P\n","\n","def policy_evaluation(policy, value_function, iterations=100, threshold=1e-8):\n","  for _ in range(iterations):\n","    new_value_function = np.zeros_like(value_function)\n","    for state in range(NUM_STATES):\n","      action = policy[state]\n","      transition_probs = transition_probability(state, action)\n","      rewards = reward(state, action)\n","      new_value_function[state] = np.sum(transition_probs * (rewards + DISCOUNT_FACTOR * value_function))\n","    change = np.abs(new_value_function - value_function).max()\n","    value_function = new_value_function\n","    if change < threshold:\n","      break\n","  return value_function\n","\n","def policy_improvement(value_function):\n","  policy = np.zeros(NUM_STATES, dtype=int)\n","  for state in range(NUM_STATES):\n","    best_action = 0\n","    best_value = -float('inf')\n","    for action in range(min(state, NUM_STATES - state) + 1):\n","      transition_probs = transition_probability(state, action)\n","      rewards = reward(state, action)\n","      expected_value = np.sum(transition_probs * (rewards + DISCOUNT_FACTOR * value_function))\n","      if expected_value > best_value:\n","        best_value = expected_value\n","        best_action = action\n","    policy[state] = best_action\n","  return policy\n","\n","\n","def policy_iteration():\n","  policy = np.ones(NUM_STATES, dtype=int) * EMPLOYEE_TRANSFER\n","  value_function = np.zeros(NUM_STATES)\n","  while True:\n","    new_value_function = policy_evaluation(policy, value_function)\n","    new_policy = policy_improvement(new_value_function)\n","    if np.array_equal(policy, new_policy):\n","      return new_policy, new_value_function\n","    policy = new_policy\n","    value_function = new_value_function\n","\n","optimal_policy, optimal_value_function = policy_iteration()\n","\n","print(\"Optimal Policy:\")\n","for state, action in enumerate(optimal_policy):\n","  print(f\"State {state} :  Move {action} cars\")\n","\n","print(\"\\nOptimal Value Function:\")\n","print(optimal_value_function)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAjrTscLH5PJ","executionInfo":{"status":"ok","timestamp":1711866566094,"user_tz":-330,"elapsed":1117,"user":{"displayName":"PRASAD JAWALE","userId":"08908178032325548227"}},"outputId":"96fdc212-f63a-4446-f3d9-8af2af3773ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimal Policy:\n","State 0 :  Move 0 cars\n","State 1 :  Move 1 cars\n","State 2 :  Move 2 cars\n","State 3 :  Move 3 cars\n","State 4 :  Move 4 cars\n","State 5 :  Move 5 cars\n","State 6 :  Move 6 cars\n","State 7 :  Move 7 cars\n","State 8 :  Move 8 cars\n","State 9 :  Move 9 cars\n","State 10 :  Move 10 cars\n","State 11 :  Move 10 cars\n","State 12 :  Move 9 cars\n","State 13 :  Move 8 cars\n","State 14 :  Move 7 cars\n","State 15 :  Move 6 cars\n","State 16 :  Move 5 cars\n","State 17 :  Move 4 cars\n","State 18 :  Move 3 cars\n","State 19 :  Move 2 cars\n","State 20 :  Move 1 cars\n","\n","Optimal Value Function:\n","[-2.00061794e+01  2.31460244e+86  2.31460247e+86  2.31460248e+86\n","  2.31460249e+86  2.31460249e+86  2.31460249e+86  2.31460249e+86\n","  2.31460250e+86  2.31460250e+86  2.31460249e+86  2.31460249e+86\n","  2.31460250e+86  2.31460250e+86  2.31460249e+86  2.31460249e+86\n","  2.31460249e+86  2.31460249e+86  2.31460248e+86  2.31460247e+86\n","  2.31460244e+86]\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"7HdgFY_MMp7h"}}]}